# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_8B7B7xYLTafbOdvc6YUKgeWZDhH24gX
"""

# -*- coding: utf-8 -*-
"""cpsc-599-project.ipynb - FIXED VERSION

Original file is located at
    https://colab.research.google.com/drive/1eA6Cy87ArIxLzleJyi52iafSKpTBp17K
"""

import kagglehub
grassknoted_asl_alphabet_path = kagglehub.dataset_download('grassknoted/asl-alphabet')
waseemnagahhenes_sign_language_dataset_wlasl_videos_path = kagglehub.dataset_download('waseemnagahhenes/sign-language-dataset-wlasl-videos')

print('Data source import complete.')

import os, random
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision.datasets import ImageFolder
from torch.utils.data import Dataset, DataLoader, Subset
from torchvision import transforms, models
from tqdm.auto import tqdm

from typing import List, Tuple

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

NUM_CLASSES_LETTERS = 29      # ASL alphabet
NUM_CLASSES_WORDS = 2000      # WLASL (if used) - could not implement this time
DATA_ROOT = os.path.join(grassknoted_asl_alphabet_path, "asl_alphabet_train")
TEST_ROOT = os.path.join(grassknoted_asl_alphabet_path, "asl_alphabet_test")
IMAGE_SIZE = 224
LEARNING_RATE = 1e-4
EPOCHS = 20
BATCH_SIZE = 64
NUM_WORKERS = 2

train_transform = transforms.Compose([
    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
    transforms.RandomApply([
        transforms.ColorJitter(brightness=0.25, contrast=0.25, saturation=0.15, hue=0.02)
    ], p=0.8),
    transforms.RandomAffine(degrees=10, translate=(0.08, 0.08), scale=(0.9, 1.1)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225]),
])

val_transform = transforms.Compose([
    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225]),
])

import os
print("Checking input directory...")
try:
    print(os.listdir(grassknoted_asl_alphabet_path))
    print(os.listdir(os.path.join(grassknoted_asl_alphabet_path, "asl_alphabet_train")))
except FileNotFoundError as e:
    print(e)

# DATASET SPLITTING - FIXED: Load once, then split and apply transforms
full_dataset = ImageFolder(DATA_ROOT)

# Reproducible split indices
val_frac = 0.1
n = len(full_dataset)
indices = torch.randperm(n, generator=torch.Generator().manual_seed(42)).tolist()
val_size = int(n * val_frac)

val_idx = indices[:val_size]
train_idx = indices[val_size:]

# Create subsets
train_ds = Subset(full_dataset, train_idx)
val_ds = Subset(full_dataset, val_idx)

# Custom wrapper to apply different transforms
class TransformSubset(Dataset):
    def __init__(self, subset, transform=None):
        self.subset = subset
        self.transform = transform

    def __getitem__(self, idx):
        img, label = self.subset[idx]
        if self.transform:
            img = self.transform(img)
        return img, label

    def __len__(self):
        return len(self.subset)

# Apply transforms
train_ds = TransformSubset(train_ds, train_transform)
val_ds = TransformSubset(val_ds, val_transform)

print("Total:", n)
print("Train:", len(train_ds), "Val:", len(val_ds))
print("Classes:", len(full_dataset.classes), full_dataset.classes[:10])

train_loader = DataLoader(
    train_ds,
    batch_size=BATCH_SIZE,
    shuffle=True,
    num_workers=NUM_WORKERS,
    pin_memory=True,
    persistent_workers=(NUM_WORKERS > 0),
    prefetch_factor=2 if NUM_WORKERS > 0 else None
)

val_loader = DataLoader(
    val_ds,
    batch_size=BATCH_SIZE,
    shuffle=False,
    num_workers=NUM_WORKERS,
    pin_memory=True,
    persistent_workers=(NUM_WORKERS > 0),
    prefetch_factor=2 if NUM_WORKERS > 0 else None
)

# Shows us size
x, y = next(iter(train_loader))
print("Batch:", x.shape, y.shape, "dtype:", x.dtype)

# Using the ResNet18 model architecture
def build_model(num_classes):
    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)
    in_features = model.fc.in_features
    model.fc = nn.Sequential(
        nn.Dropout(0.3),
        nn.Linear(in_features, num_classes)
    )
    return model

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
model = build_model(NUM_CLASSES_LETTERS).to(DEVICE)

criterion = nn.CrossEntropyLoss(label_smoothing=0.05)
optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)
scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)

from torch.amp import autocast, GradScaler
scaler = GradScaler(enabled=(DEVICE == "cuda"))

def train_one_epoch(model, loader, epoch):
    model.train()
    total_loss = 0.0

    pbar = tqdm(loader, desc=f"Epoch {epoch:02d} [train]", leave=False)
    try:
        for x, y in pbar:
            x, y = x.to(DEVICE, non_blocking=True), y.to(DEVICE, non_blocking=True)
            optimizer.zero_grad(set_to_none=True)

            with autocast(device_type="cuda", enabled=(DEVICE == "cuda")):
                out = model(x)
                loss = criterion(out, y)

            scaler.scale(loss).backward()
            nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            scaler.step(optimizer)
            scaler.update()

            total_loss += loss.item()
            pbar.set_postfix(loss=f"{loss.item():.4f}")
    finally:
        pbar.close()

    return total_loss / len(loader)

# Use no grad as we want inferences in a tighter time loop through our webcam
@torch.no_grad()
def eval_one_epoch(model, loader, desc="[val]"):
    model.eval()
    total_loss, correct, total = 0.0, 0, 0

    pbar = tqdm(loader, desc=f"           {desc}", leave=False)
    try:
        for x, y in pbar:
            x, y = x.to(DEVICE, non_blocking=True), y.to(DEVICE, non_blocking=True)

            with autocast(device_type="cuda", enabled=(DEVICE == "cuda")):
                out = model(x)
                loss = criterion(out, y)

            total_loss += loss.item()
            pred = out.argmax(1)
            correct += (pred == y).sum().item()
            total += y.size(0)

            acc = correct / total
            pbar.set_postfix(loss=f"{loss.item():.4f}", acc=f"{acc:.3f}")
    finally:
        pbar.close()

    return total_loss / len(loader), correct / total

# Training loop
best_val_loss = float("inf")
train_losses = []
val_losses = []
val_accs = []

# FIXED: Use EPOCHS constant
for epoch in range(1, EPOCHS + 1):
    print(f"\n=== Epoch {epoch:02d}/{EPOCHS} ===")

    tr_loss = train_one_epoch(model, train_loader, epoch)
    va_loss, va_acc = eval_one_epoch(model, val_loader, desc="[val]")
    scheduler.step()

    print(
        f"Epoch {epoch:02d} | "
        f"train loss {tr_loss:.4f} | "
        f"val loss {va_loss:.4f} | "
        f"val acc {va_acc:.4f}"
    )

    train_losses.append(tr_loss)
    val_losses.append(va_loss)
    val_accs.append(va_acc)

    if va_loss < best_val_loss:
        best_val_loss = va_loss
        torch.save({
            "model_state": model.state_dict(),
            "classes": full_dataset.classes,
            "image_size": IMAGE_SIZE,
            "best_val_loss": best_val_loss,
            "epoch": epoch,
        }, "asl_resnet18_best.pth")
        print(f"âœ“ Saved new best val loss: {best_val_loss:.4f}")

# FIXED: Load best model and evaluate on test set
print("\n" + "="*50)
print("Loading best model for test evaluation...")
checkpoint = torch.load("asl_resnet18_best.pth")
model.load_state_dict(checkpoint["model_state"])
print(f"Best model from epoch {checkpoint['epoch']} (val loss: {checkpoint['best_val_loss']:.4f})")

# Load test dataset
print("Loading test dataset...")
test_dataset = ImageFolder(TEST_ROOT, transform=val_transform)
test_loader = DataLoader(
    test_dataset,
    batch_size=BATCH_SIZE,
    shuffle=False,
    num_workers=NUM_WORKERS,
    pin_memory=True
)
print(f"Test dataset size: {len(test_dataset)}")

# Evaluate on test set
print("Evaluating on test set...")
test_loss, test_acc = eval_one_epoch(model, test_loader, desc="[test]")
print(f"\n{'='*50}")
print(f"FINAL TEST RESULTS:")
print(f"Test Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)")
print(f"{'='*50}\n")

# Plotting
import matplotlib.pyplot as plt

epochs = range(1, len(train_losses) + 1)

# ---- Loss plot ----
plt.figure(figsize=(10, 5))
plt.plot(epochs, train_losses, label="Train Loss", marker='o')
plt.plot(epochs, val_losses, label="Val Loss", marker='s')
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Training vs Validation Loss")
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

# ---- Accuracy plot ----
plt.figure(figsize=(10, 5))
plt.plot(epochs, val_accs, label="Val Accuracy", marker='o', color='green')
plt.axhline(y=test_acc, color='r', linestyle='--', label=f'Test Accuracy ({test_acc:.4f})')
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.title("Validation Accuracy Over Training")
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

print("Training complete! Model saved as 'asl_resnet18_best.pth'")