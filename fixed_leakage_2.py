# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15gquuhFRQcdLwewy-a9zW1EdWPePRHg3
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.
import kagglehub
grassknoted_asl_alphabet_path = kagglehub.dataset_download('grassknoted/asl-alphabet')
waseemnagahhenes_sign_language_dataset_wlasl_videos_path = kagglehub.dataset_download('waseemnagahhenes/sign-language-dataset-wlasl-videos')

print('Data source import complete.')

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import models, transforms
from PIL import Image
import numpy as np
from tqdm import tqdm
from pathlib import Path
import json
from sklearn.model_selection import train_test_split
import kagglehub

# Download datasets
print("Downloading datasets...")
grassknoted_asl_alphabet_path = kagglehub.dataset_download('grassknoted/asl-alphabet')
print(f"ASL Alphabet dataset path: {grassknoted_asl_alphabet_path}")

# Uncomment if you want to use WLASL dataset later
# waseemnagahhenes_sign_language_dataset_wlasl_videos_path = kagglehub.dataset_download('waseemnagahhenes/sign-language-dataset-wlasl-videos')
# print(f"WLASL dataset path: {waseemnagahhenes_sign_language_dataset_wlasl_videos_path}")

print('Data source import complete.')

# Set device
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {DEVICE}")

# Hyperparameters
BATCH_SIZE = 32
NUM_EPOCHS = 10
LEARNING_RATE = 0.001
IMAGE_SIZE = 224
EARLY_STOPPING_PATIENCE = 7
VALIDATION_SPLIT = 0.15

class ASLDataset(Dataset):
    """Custom Dataset for ASL images"""
    def __init__(self, image_paths, labels, transform=None):
        self.image_paths = image_paths
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        label = self.labels[idx]

        try:
            # Load image
            image = Image.open(img_path).convert('RGB')

            if self.transform:
                image = self.transform(image)

            return image, label
        except Exception as e:
            print(f"Error loading image {img_path}: {e}")
            # Return a blank image if there's an error
            blank_img = Image.new('RGB', (IMAGE_SIZE, IMAGE_SIZE), (0, 0, 0))
            if self.transform:
                blank_img = self.transform(blank_img)
            return blank_img, label

def load_asl_alphabet_dataset(data_dir):
    """
    Load ASL Alphabet dataset from kagglehub download path
    The structure is typically:
    data_dir/
        asl_alphabet_train/
            asl_alphabet_train/
                A/
                B/
                ...
    """
    image_paths = []
    labels = []
    class_names = []

    data_path = Path(data_dir)
    print(f"Exploring data directory: {data_path}")

    # Find the actual train folder (kagglehub structure can be nested)
    train_folder = None
    for item in data_path.rglob("*"):
        if item.is_dir() and ('train' in item.name.lower() or 'asl_alphabet_train' in item.name.lower()):
            # Check if this folder contains class subfolders
            subfolders = [f for f in item.iterdir() if f.is_dir()]
            if len(subfolders) > 20:  # ASL has 29 classes
                train_folder = item
                break

    # If no train folder found, use the data_path itself
    if train_folder is None:
        # Look for direct class folders
        potential_class_folders = [f for f in data_path.iterdir() if f.is_dir()]
        if len(potential_class_folders) > 20:
            train_folder = data_path
        else:
            # Try one level deeper
            for subfolder in data_path.iterdir():
                if subfolder.is_dir():
                    sub_subfolders = [f for f in subfolder.iterdir() if f.is_dir()]
                    if len(sub_subfolders) > 20:
                        train_folder = subfolder
                        break

    if train_folder is None:
        raise ValueError(f"Could not find training data in {data_path}. Please check the dataset structure.")

    print(f"Found training folder: {train_folder}")

    # Get all class folders (A, B, C, ..., SPACE, DELETE, NOTHING)
    class_folders = sorted([f for f in train_folder.iterdir() if f.is_dir()])

    print(f"Found {len(class_folders)} class folders")

    for idx, class_folder in enumerate(class_folders):
        class_name = class_folder.name
        class_names.append(class_name)

        # Get all images in this class folder
        image_files = list(class_folder.glob("*.jpg")) + \
                     list(class_folder.glob("*.png")) + \
                     list(class_folder.glob("*.jpeg")) + \
                     list(class_folder.glob("*.JPG"))

        print(f"Class {class_name}: {len(image_files)} images")

        for img_file in image_files:
            image_paths.append(str(img_file))
            labels.append(idx)

    print(f"\nTotal: {len(image_paths)} images from {len(class_names)} classes")
    print(f"Classes: {class_names}")

    return image_paths, labels, class_names

def get_transforms(augment=True):
    """Get data augmentation transforms"""
    if augment:
        # Training transforms with augmentation
        transform = transforms.Compose([
            transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
            transforms.RandomRotation(20),
            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
            transforms.RandomHorizontalFlip(p=0.3),
            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],  # ImageNet stats
                std=[0.229, 0.224, 0.225]
            ),
            transforms.RandomErasing(p=0.2, scale=(0.02, 0.15))
        ])
    else:
        # Validation/test transforms (no augmentation)
        transform = transforms.Compose([
            transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])

    return transform

def build_model(num_classes, model_name='resnet18'):
    """Build the model architecture"""
    if model_name == 'resnet18':
        model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)
        in_features = model.fc.in_features
        model.fc = nn.Sequential(
            nn.Dropout(0.3),
            nn.Linear(in_features, num_classes)
        )
    elif model_name == 'resnet50':
        model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)
        in_features = model.fc.in_features
        model.fc = nn.Sequential(
            nn.Dropout(0.4),
            nn.Linear(in_features, num_classes)
        )
    elif model_name == 'mobilenet_v2':
        model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)
        in_features = model.classifier[1].in_features
        model.classifier = nn.Sequential(
            nn.Dropout(0.3),
            nn.Linear(in_features, num_classes)
        )

    return model

def train_epoch(model, dataloader, criterion, optimizer, device):
    """Train for one epoch"""
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    pbar = tqdm(dataloader, desc='Training')
    for images, labels in pbar:
        images, labels = images.to(device), labels.to(device)

        # Forward pass
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)

        # Backward pass
        loss.backward()
        optimizer.step()

        # Statistics
        running_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

        # Update progress bar
        pbar.set_postfix({
            'loss': f'{running_loss/len(dataloader):.4f}',
            'acc': f'{100.*correct/total:.2f}%'
        })

    epoch_loss = running_loss / len(dataloader)
    epoch_acc = 100. * correct / total

    return epoch_loss, epoch_acc

def validate(model, dataloader, criterion, device):
    """Validate the model"""
    model.eval()
    running_loss = 0.0
    correct = 0
    total = 0

    with torch.no_grad():
        pbar = tqdm(dataloader, desc='Validation')
        for images, labels in pbar:
            images, labels = images.to(device), labels.to(device)

            outputs = model(images)
            loss = criterion(outputs, labels)

            running_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

            pbar.set_postfix({
                'loss': f'{running_loss/len(dataloader):.4f}',
                'acc': f'{100.*correct/total:.2f}%'
            })

    epoch_loss = running_loss / len(dataloader)
    epoch_acc = 100. * correct / total

    return epoch_loss, epoch_acc

def main():
    # Load dataset
    print("\n" + "="*50)
    print("Loading ASL Alphabet Dataset")
    print("="*50)

    image_paths, labels, class_names = load_asl_alphabet_dataset(grassknoted_asl_alphabet_path)

    # Split into train and validation
    train_paths, val_paths, train_labels, val_labels = train_test_split(
        image_paths, labels, test_size=VALIDATION_SPLIT, random_state=42, stratify=labels
    )

    print(f"\nTraining samples: {len(train_paths)}")
    print(f"Validation samples: {len(val_paths)}")

    # Create datasets
    train_dataset = ASLDataset(train_paths, train_labels, transform=get_transforms(augment=True))
    val_dataset = ASLDataset(val_paths, val_labels, transform=get_transforms(augment=False))

    # Create dataloaders
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)

    # Build model
    print("\n" + "="*50)
    print("Building Model")
    print("="*50)

    model = build_model(len(class_names), model_name='resnet18').to(DEVICE)
    print(f"Model: ResNet18")
    print(f"Number of classes: {len(class_names)}")

    # Loss and optimizer
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)

    # Training loop
    print("\n" + "="*50)
    print("Starting Training")
    print("="*50)

    best_val_acc = 0.0
    epochs_no_improve = 0
    history = {
        'train_loss': [], 'train_acc': [],
        'val_loss': [], 'val_acc': []
    }

    for epoch in range(NUM_EPOCHS):
        print(f"\nEpoch {epoch+1}/{NUM_EPOCHS}")
        print("-" * 50)

        # Train
        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, DEVICE)
        history['train_loss'].append(train_loss)
        history['train_acc'].append(train_acc)

        # Validate
        val_loss, val_acc = validate(model, val_loader, criterion, DEVICE)
        history['val_loss'].append(val_loss)
        history['val_acc'].append(val_acc)

        # Learning rate scheduling
        scheduler.step(val_loss)

        print(f"\nEpoch {epoch+1} Summary:")
        print(f"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%")
        print(f"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%")

        # Save best model
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            epochs_no_improve = 0

            checkpoint = {
                'epoch': epoch,
                'model_state': model.state_dict(),
                'optimizer_state': optimizer.state_dict(),
                'val_acc': val_acc,
                'classes': class_names,
                'image_size': IMAGE_SIZE
            }
            torch.save(checkpoint, 'asl_resnet18_best.pth')
            print(f"âœ“ New best model saved! Val Acc: {val_acc:.2f}%")
        else:
            epochs_no_improve += 1
            print(f"No improvement for {epochs_no_improve} epoch(s)")

        # Early stopping
        if epochs_no_improve >= EARLY_STOPPING_PATIENCE:
            print(f"\nEarly stopping triggered after {epoch+1} epochs")
            break

    # Save final model
    final_checkpoint = {
        'epoch': epoch,
        'model_state': model.state_dict(),
        'optimizer_state': optimizer.state_dict(),
        'val_acc': val_acc,
        'classes': class_names,
        'image_size': IMAGE_SIZE,
        'history': history
    }
    torch.save(final_checkpoint, 'asl_resnet18_final.pth')

    print("\n" + "="*50)
    print("Training Complete!")
    print("="*50)
    print(f"Best Validation Accuracy: {best_val_acc:.2f}%")
    print(f"Models saved:")
    print(f"  - asl_resnet18_best.pth (best validation accuracy)")
    print(f"  - asl_resnet18_final.pth (final epoch)")

if __name__ == "__main__":
    main()